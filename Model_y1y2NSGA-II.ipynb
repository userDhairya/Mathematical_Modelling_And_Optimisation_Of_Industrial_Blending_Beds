{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**1.Data Import and Library Integration**"
   ],
   "metadata": {
    "id": "-Uz44K1xkV7z"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q_42slQM_ftt"
   },
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.mutation.pm import PolynomialMutation\n",
    "import plotly.graph_objects as go"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5367,
     "status": "ok",
     "timestamp": 1725061642367,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "yHwSG2gI_kbh",
    "outputId": "869565f4-756e-499d-ac30-3b5be1e80a09"
   },
   "source": [
    "# upload dataset\n",
    "file_path = './matrix_f1_f2_200,000.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "print(data.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.Model Training, Evaluation, and Optimization Workflow**"
   ],
   "metadata": {
    "id": "6XSqpZtEk4_v"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29246,
     "status": "ok",
     "timestamp": 1725061671610,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "xRSujXA4z_Jw",
    "outputId": "3f1eccdd-ee27-405e-e9de-ab0505772047"
   },
   "source": [
    "### Model1 for y1 ###\n",
    "# Prepare the data for Model1 (y1)\n",
    "X = data.drop(columns=['y1', 'y2'])\n",
    "y1 = data['y1']\n",
    "\n",
    "# Split the data into training and testing sets for y1\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with StandardScaler and Lasso using the specified alpha\n",
    "pipeline1 = make_pipeline(StandardScaler(), Lasso(alpha=0.0001, max_iter=10000))\n",
    "\n",
    "# Fit the model on the training data\n",
    "pipeline1.fit(X_train, y1_train)\n",
    "model1 = pipeline1\n",
    "\n",
    "# Predict on the test set for y1\n",
    "y1_pred = model1.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) and R² on the test set for y1\n",
    "mse_y1 = mean_squared_error(y1_test, y1_pred)\n",
    "r2_y1 = r2_score(y1_test, y1_pred)\n",
    "\n",
    "print(\"Model1 - y1:\")\n",
    "print(\"Alpha used:\", 0.0001)\n",
    "print(\"Mean Squared Error (MSE) on Test Set:\", mse_y1)\n",
    "print(\"R² Score on Test Set:\", r2_y1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 2763,
     "status": "ok",
     "timestamp": 1724443625770,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "_Tu52jQR1kUh",
    "outputId": "5d01d6e2-463b-4afc-ab37-b12e162f5ee1"
   },
   "source": [
    "def plot_actual_vs_predicted(y_true, y_pred, title, xaxis_title, yaxis_title):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Actual vs. Predicted\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            mode='markers',\n",
    "            x=y_true,\n",
    "            y=y_pred,\n",
    "            marker=dict(\n",
    "                color='rgba(40, 40, 250, 0.3)',\n",
    "                size=5,\n",
    "            ),\n",
    "            name='Actual vs Predicted'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add a 45-degree line to show the perfect prediction\n",
    "    min_value = min(y_true.min(), y_pred.min())\n",
    "    max_value = max(y_true.max(), y_pred.max())\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_value, max_value],\n",
    "            y=[min_value, max_value],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', dash='dash'),\n",
    "            showlegend=False,\n",
    "            name='Perfect Prediction Line'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=xaxis_title,\n",
    "        yaxis_title=yaxis_title,\n",
    "        width=700,\n",
    "        height=500,\n",
    "        xaxis=dict(range=[min_value, max_value]),\n",
    "        yaxis=dict(range=[min_value, max_value])\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "# Plot for Model1 (y1)\n",
    "plot_actual_vs_predicted(y1_test, y1_pred, \"Actual vs Predicted y1 Values (Model1)\", \"Actual y1\", \"Predicted y1\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6kJY3TUK1DVQ",
    "outputId": "6ef6be76-7dac-4f25-9ed3-ea8a489cba0d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1725062084728,
     "user_tz": -60,
     "elapsed": 413131,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     }
    }
   },
   "source": [
    "X = data.drop(columns=['y1', 'y2'])\n",
    "y2 = data['y2']\n",
    "\n",
    "# Split the data into training and testing sets for y2\n",
    "X_train, X_test, y2_train, y2_test = train_test_split(X, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with StandardScaler and Lasso using the specified alpha\n",
    "pipeline2 = make_pipeline(StandardScaler(), Lasso(alpha=0.0001, max_iter=50000))\n",
    "\n",
    "# Fit the model on the training data\n",
    "pipeline2.fit(X_train, y2_train)\n",
    "model2 = pipeline2\n",
    "\n",
    "# Predict on the test set for y2\n",
    "y2_pred = model2.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) and R² on the test set for y2\n",
    "mse_y2 = mean_squared_error(y2_test, y2_pred)\n",
    "r2_y2 = r2_score(y2_test, y2_pred)\n",
    "\n",
    "print(\"Model2 - y2:\")\n",
    "print(\"Alpha used:\", 0.0001)\n",
    "print(\"Mean Squared Error (MSE) on Test Set:\", mse_y2)\n",
    "print(\"R² Score on Test Set:\", r2_y2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "executionInfo": {
     "elapsed": 1517,
     "status": "ok",
     "timestamp": 1724444056276,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "i8LIIbcp1Jog",
    "outputId": "5a51b46e-bb8d-4e36-9b05-bb12bb1cebb4"
   },
   "source": [
    "def plot_actual_vs_predicted(y_true, y_pred, title, xaxis_title, yaxis_title):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Actual vs. Predicted\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            mode='markers',\n",
    "            x=y_true,\n",
    "            y=y_pred,\n",
    "            marker=dict(\n",
    "                color='rgba(40, 40, 250, 0.3)',\n",
    "                size=5,\n",
    "            ),\n",
    "            name='Actual vs Predicted'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add a 45-degree line to show the perfect prediction\n",
    "    min_value = min(y_true.min(), y_pred.min())\n",
    "    max_value = max(y_true.max(), y_pred.max())\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_value, max_value],\n",
    "            y=[min_value, max_value],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', dash='dash'),\n",
    "            showlegend=False,\n",
    "            name='Perfect Prediction Line'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=xaxis_title,\n",
    "        yaxis_title=yaxis_title,\n",
    "        width=700,\n",
    "        height=500,\n",
    "        xaxis=dict(range=[min_value, max_value]),\n",
    "        yaxis=dict(range=[min_value, max_value])\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "# Plot for Model2 (y2)\n",
    "plot_actual_vs_predicted(y2_test, y2_pred, \"Actual vs Predicted y2 Values (Model2)\", \"Actual y2\", \"Predicted y2\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uf3EzsCA3olW",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1725062138883,
     "user_tz": -60,
     "elapsed": 28471,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     }
    },
    "outputId": "fe47f4a5-989b-4525-d89a-be9330171196"
   },
   "source": [
    "#XGBoost Model3\n",
    "X = data.drop(columns=['y1', 'y2'])\n",
    "y1 = data['y1']\n",
    "\n",
    "# Split the data into training and testing sets for y1\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBoost regressor with L1 regularization (alpha) for model3\n",
    "model3 = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    alpha=0.5,  # L1 regularization parameter\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on the training data for y1\n",
    "model3.fit(X_train, y1_train)\n",
    "\n",
    "# Evaluate on the test set for y1\n",
    "y1_pred = model3.predict(X_test)\n",
    "test_mse_y1 = mean_squared_error(y1_test, y1_pred)\n",
    "r2_y1 = r2_score(y1_test, y1_pred)\n",
    "\n",
    "print(\"Test MSE:\", test_mse_y1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract the initial values from row 14 for columns X1-X50\n",
    "initial_values = data.iloc[13, 2:52].values  # Extracting X1-X50 from row 14\n",
    "\n",
    "# Define the optimization problem\n",
    "class F1F2Problem(Problem):\n",
    "    def __init__(self, model_y1, model_y2, initial_values):\n",
    "        n_var = 70  # Total number of features\n",
    "        xl_x1_x50 = initial_values  # Fix X1-X50\n",
    "        xu_x1_x50 = initial_values  # Fix X1-X50\n",
    "\n",
    "        # Define the range for X51-X70 (10 to 49)\n",
    "        xl_x51_x70 = np.full(20, 10)\n",
    "        xu_x51_x70 = np.full(20, 49)\n",
    "\n",
    "        # Combine all the variable bounds\n",
    "        xl = np.concatenate((xl_x1_x50, xl_x51_x70))\n",
    "        xu = np.concatenate((xu_x1_x50, xu_x51_x70))\n",
    "\n",
    "        super().__init__(n_var=n_var, n_obj=2, n_constr=0, xl=xl, xu=xu)\n",
    "        self.model_y1 = model_y1\n",
    "        self.model_y2 = model_y2\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        # Scale the input data\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        # Predict F1 and F2 using the trained Lasso models\n",
    "        f1 = self.model_y1.predict(X_scaled)\n",
    "        f2 = self.model_y2.predict(X_scaled)\n",
    "        out[\"F\"] = np.column_stack([f1, f2])\n",
    "\n",
    "# Create the problem instance for model1 and model2\n",
    "problem = F1F2Problem(model_y1=model1, model_y2=model2, initial_values=initial_values)\n",
    "\n",
    "# Define the algorithm with updated parameters\n",
    "algorithm = NSGA2(\n",
    "    pop_size=100,  # Population size\n",
    "    sampling=FloatRandomSampling(),\n",
    "    crossover=SBX(prob=0.95, eta=10),  # Crossover probability and eta\n",
    "    mutation=PolynomialMutation(prob=0.25, eta=25)  # Mutation rate\n",
    ")\n",
    "\n",
    "# Set up colors for the different runs\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Set a fixed seed for all runs to make them identical\n",
    "fixed_seed = 42\n",
    "\n",
    "# Create a figure for the combined plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Loop to run the optimization 5 times and plot the Pareto fronts in different colors\n",
    "for i in range(5):\n",
    "    # Execute the optimization with the fixed seed\n",
    "    res = minimize(problem, algorithm, ('n_gen', 100), seed=fixed_seed + i, save_history=True, verbose=True)\n",
    "\n",
    "    # Plot the Pareto Frontier for this run in a different color\n",
    "    plt.scatter(res.F[:, 0], res.F[:, 1], color=colors[i], label=f'Run {i+1}')\n",
    "\n",
    "# Calculate the min and max values for f1 and f2 across all runs\n",
    "f1_min, f1_max = res.F[:, 0].min(), res.F[:, 0].max()\n",
    "f2_min, f2_max = res.F[:, 1].min(), res.F[:, 1].max()\n",
    "\n",
    "# Add some padding for better visualization\n",
    "f1_range = f1_max - f1_min\n",
    "f2_range = f2_max - f2_min\n",
    "\n",
    "plt.xlim(f1_min - 0.05 * f1_range, f1_max + 0.05 * f1_range)  # Set the range for f1 on the x-axis\n",
    "plt.ylim(f2_min - 0.05 * f2_range, f2_max + 0.05 * f2_range)  # Set the range for f2 on the y-axis\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Objective 1 (f1)')\n",
    "plt.ylabel('Objective 2 (f2)')\n",
    "plt.title('Pareto Front for NSGA-II with Lasso Model')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot for Model3 (y1)\n",
    "def plot_actual_vs_predicted(y_true, y_pred, title, xaxis_title, yaxis_title):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Actual vs. Predicted\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            mode='markers',\n",
    "            x=y_true,\n",
    "            y=y_pred,\n",
    "            marker=dict(\n",
    "                color='rgba(40, 40, 250, 0.3)',\n",
    "                size=5,\n",
    "            ),\n",
    "            name='Actual vs Predicted'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add a 45-degree line to show the perfect prediction\n",
    "    min_value = min(y_true.min(), y_pred.min())\n",
    "    max_value = max(y_true.max(), y_pred.max())\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_value, max_value],\n",
    "            y=[min_value, max_value],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', dash='dash'),\n",
    "            showlegend=False,\n",
    "            name='Perfect Prediction Line'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=xaxis_title,\n",
    "        yaxis_title=yaxis_title,\n",
    "        width=700,\n",
    "        height=500,\n",
    "        xaxis=dict(range=[min_value, max_value]),\n",
    "        yaxis=dict(range=[min_value, max_value])\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "# Plot the predicted vs actual values for y1 (Model3)\n",
    "plot_actual_vs_predicted(y1_test, y1_pred, \"Actual vs Predicted y1 Values (Model3)\", \"Actual y1\", \"Predicted y1\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fxPs7he23tWg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1725062165998,
     "user_tz": -60,
     "elapsed": 27130,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     }
    },
    "outputId": "abf5225d-5515-4304-f32c-83a152f55b52"
   },
   "source": [
    "X = data.drop(columns=['y1', 'y2'])\n",
    "y2 = data['y2']\n",
    "\n",
    "# Split the data into training and testing sets for y2\n",
    "X_train, X_test, y2_train, y2_test = train_test_split(X, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBoost regressor with L1 regularization (alpha) for model4\n",
    "model4 = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    alpha=0.5,  # L1 regularization parameter\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on the training data for y2\n",
    "model4.fit(X_train, y2_train)\n",
    "\n",
    "# Evaluate on the test set for y2\n",
    "y2_pred = model4.predict(X_test)\n",
    "test_mse_y2 = mean_squared_error(y2_test, y2_pred)\n",
    "r2_y2 = r2_score(y2_test, y2_pred)\n",
    "\n",
    "print(\"Test MSE:\", test_mse_y2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "executionInfo": {
     "elapsed": 1298,
     "status": "ok",
     "timestamp": 1724444130590,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "0djsXco94daA",
    "outputId": "cb67269d-a5c8-4fbd-9d76-a9845fdea58d"
   },
   "source": [
    "# Plot for Model4 (y2)\n",
    "def plot_actual_vs_predicted(y_true, y_pred, title, xaxis_title, yaxis_title):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Actual vs. Predicted\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            mode='markers',\n",
    "            x=y_true,\n",
    "            y=y_pred,\n",
    "            marker=dict(\n",
    "                color='rgba(40, 40, 250, 0.3)',\n",
    "                size=5,\n",
    "            ),\n",
    "            name='Actual vs Predicted'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add a 45-degree line to show the perfect prediction\n",
    "    min_value = min(y_true.min(), y_pred.min())\n",
    "    max_value = max(y_true.max(), y_pred.max())\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_value, max_value],\n",
    "            y=[min_value, max_value],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', dash='dash'),\n",
    "            showlegend=False,\n",
    "            name='Perfect Prediction Line'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=xaxis_title,\n",
    "        yaxis_title=yaxis_title,\n",
    "        width=700,\n",
    "        height=500,\n",
    "        xaxis=dict(range=[min_value, max_value]),\n",
    "        yaxis=dict(range=[min_value, max_value])\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "# Plot the predicted vs actual values for y2 (Model4)\n",
    "plot_actual_vs_predicted(y2_test, y2_pred, \"Actual vs Predicted y2 Values (Model4)\", \"Actual y2\", \"Predicted y2\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 51269,
     "status": "ok",
     "timestamp": 1725062217262,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "T5v9_KCT5uro",
    "outputId": "8b3ed99e-e18c-4338-ac19-c3d84d4a1640"
   },
   "source": [
    "# Extract the initial values from row 14 for columns X1-X50\n",
    "initial_values = data.iloc[13, 2:52].values  # Extracting X1-X50 from row 14\n",
    "\n",
    "# Define the optimization problem\n",
    "class F1F2Problem(Problem):\n",
    "    def __init__(self, model_y1, model_y2, initial_values):\n",
    "        n_var = 70  # Total number of features\n",
    "        xl_x1_x50 = initial_values  # Fix X1-X50\n",
    "        xu_x1_x50 = initial_values  # Fix X1-X50\n",
    "\n",
    "        # Define the range for X51-X70 (10 to 49)\n",
    "        xl_x51_x70 = np.full(20, 10)\n",
    "        xu_x51_x70 = np.full(20, 49)\n",
    "\n",
    "        # Combine all the variable bounds\n",
    "        xl = np.concatenate((xl_x1_x50, xl_x51_x70))\n",
    "        xu = np.concatenate((xu_x1_x50, xu_x51_x70))\n",
    "\n",
    "        super().__init__(n_var=n_var, n_obj=2, n_constr=0, xl=xl, xu=xu)\n",
    "        self.model_y1 = model_y1\n",
    "        self.model_y2 = model_y2\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        # Scale the input data\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        # Predict F1 and F2 using the trained models\n",
    "        f1 = self.model_y1.predict(X_scaled)\n",
    "        f2 = self.model_y2.predict(X_scaled)\n",
    "        out[\"F\"] = np.column_stack([f1, f2])\n",
    "\n",
    "# Create the problem instance for model3 and model4\n",
    "problem = F1F2Problem(model_y1=model3, model_y2=model4, initial_values=initial_values)\n",
    "\n",
    "# Define the algorithm with updated parameters\n",
    "algorithm = NSGA2(\n",
    "    pop_size=100,  # Population size\n",
    "    sampling=FloatRandomSampling(),\n",
    "    crossover=SBX(prob=0.95, eta=10),  # Crossover probability and eta\n",
    "    mutation=PolynomialMutation(prob=0.25, eta=25)  # Mutation rate\n",
    ")\n",
    "\n",
    "# Set up colors for the different runs\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Set a fixed seed for all runs to make them identical\n",
    "fixed_seed = 42\n",
    "\n",
    "# Create a figure for the combined plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Loop to run the optimization 5 times and plot the Pareto fronts in different colors\n",
    "for i in range(5):\n",
    "    # Execute the optimization with the fixed seed\n",
    "    res = minimize(problem, algorithm, ('n_gen', 100), seed=fixed_seed + i, save_history=True, verbose=True)\n",
    "\n",
    "    # Plot the Pareto Frontier for this run in a different color\n",
    "    plt.scatter(res.F[:, 0], res.F[:, 1], color=colors[i], label=f'Run {i+1}')\n",
    "\n",
    "# Calculate the min and max values for f1 and f2 across all runs\n",
    "f1_min, f1_max = res.F[:, 0].min(), res.F[:, 0].max()\n",
    "f2_min, f2_max = res.F[:, 1].min(), res.F[:, 1].max()\n",
    "\n",
    "# Add some padding for better visualization\n",
    "f1_range = f1_max - f1_min\n",
    "f2_range = f2_max - f2_min\n",
    "\n",
    "plt.xlim(f1_min - 0.05 * f1_range, f1_max + 0.05 * f1_range)  # Set the range for f1 on the x-axis\n",
    "plt.ylim(f2_min - 0.05 * f2_range, f2_max + 0.05 * f2_range)  # Set the range for f2 on the y-axis\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Objective 1 (f1)')\n",
    "plt.ylabel('Objective 2 (f2)')\n",
    "plt.title('Pareto Front for NSGA-II with XGBoost Model')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YWy02KkW_sUg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1725062497263,
     "user_tz": -60,
     "elapsed": 280010,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     }
    },
    "outputId": "9d0ebe7a-67fa-4324-aa2d-02f221f0d415"
   },
   "source": [
    "# Prepare the data for y1:64/32:0.019(PCA:0.022); 32:0.022; 128/64/32:0.031;\n",
    "# MLP Prepare the data for y1\n",
    "X = data.drop(columns=['y1', 'y2'])\n",
    "y1 = data[['y1']]\n",
    "\n",
    "# Split the data into training and testing sets for y1\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the MLP model for y1 (model5)\n",
    "model5 = Sequential()\n",
    "model5.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(32, activation='relu'))\n",
    "model5.add(Dense(1, activation='linear'))  # One output node for y1\n",
    "\n",
    "# Compile the model\n",
    "model5.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping_y1 = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model and measure time\n",
    "start_time_model5 = time.time()\n",
    "history5 = model5.fit(X_train_scaled, y1_train, validation_split=0.2, epochs=100, batch_size=32, verbose=1, callbacks=[early_stopping_y1])\n",
    "end_time_model5 = time.time()\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_model5 = model5.evaluate(X_test_scaled, y1_test)\n",
    "print(f\"Test MSE for y1 (model5): {test_loss_model5}\")\n",
    "\n",
    "# Predict on test data\n",
    "y1_pred = model5.predict(X_test_scaled)\n",
    "\n",
    "train_time_model5 = end_time_model5 - start_time_model5\n",
    "print(f\"Training time for y1 model (model5): {train_time_model5} seconds\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "executionInfo": {
     "elapsed": 1481,
     "status": "ok",
     "timestamp": 1724444550045,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "qTMVsM7oAfDN",
    "outputId": "03a12d8c-7ac9-47ee-d3d2-5bee82cc4496"
   },
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_actual_vs_predicted_y1(y_true, y_pred, title):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Actual vs. Predicted for y1\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            mode='markers',\n",
    "            x=y_true.flatten(),\n",
    "            y=y_pred.flatten(),\n",
    "            marker=dict(\n",
    "                color='rgba(40, 40, 250, 0.3)',\n",
    "                size=5,\n",
    "            ),\n",
    "            name='Actual vs Predicted'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add a 45-degree line to show the perfect prediction\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 3],\n",
    "            y=[0, 3],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', dash='dash'),\n",
    "            showlegend=False,\n",
    "            name='Perfect Prediction Line'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Actual y1\",\n",
    "        yaxis_title=\"Predicted y1\",\n",
    "        width=700,\n",
    "        height=500,\n",
    "        xaxis=dict(range=[0, 3]),\n",
    "        yaxis=dict(range=[0, 3])\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "# Plot for model5 (y1)\n",
    "plot_actual_vs_predicted_y1(y1_test.values, y1_pred, \"Actual vs Predicted y1 Values (Model5)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hNBxiis0_4iM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1725062750293,
     "user_tz": -60,
     "elapsed": 253039,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     }
    },
    "outputId": "7f31809d-5218-43a0-c88b-bd3cc59ba49a"
   },
   "source": [
    "#5times or around to trade-off 100，000：6.29；200，000：3.99;500,000:5.01\n",
    "#test set; unseen data (userbility)\n",
    "# Prepare the data for y2\n",
    "X = data.drop(columns=['y1', 'y2'])\n",
    "y2 = data[['y2']]\n",
    "\n",
    "# Split the data into training and testing sets for y2\n",
    "X_train, X_test, y2_train, y2_test = train_test_split(X, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the MLP model for y2 (model6)\n",
    "model6 = Sequential()\n",
    "model6.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(32, activation='relu'))\n",
    "model6.add(Dense(1, activation='linear'))  # One output node for y2\n",
    "\n",
    "# Compile the model\n",
    "model6.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping_y2 = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model and measure time\n",
    "start_time_model6 = time.time()\n",
    "history6 = model6.fit(X_train_scaled, y2_train, validation_split=0.2, epochs=100, batch_size=32, verbose=1, callbacks=[early_stopping_y2])\n",
    "end_time_model6 = time.time()\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_model6 = model6.evaluate(X_test_scaled, y2_test)\n",
    "print(f\"Test MSE for y2 (model6): {test_loss_model6}\")\n",
    "\n",
    "# Predict on test data\n",
    "y2_pred = model6.predict(X_test_scaled)\n",
    "\n",
    "train_time_model6 = end_time_model6 - start_time_model6\n",
    "print(f\"Training time for y2 model (model6): {train_time_model6} seconds\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "executionInfo": {
     "elapsed": 2071,
     "status": "ok",
     "timestamp": 1724444846602,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "chlIG4Lk3i9_",
    "outputId": "c1798d70-3273-445b-ca24-2c7ed14639ec"
   },
   "source": [
    "def plot_actual_vs_predicted_y2(y_true, y_pred, title):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Actual vs. Predicted for y2\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            mode='markers',\n",
    "            x=y_true.flatten(),\n",
    "            y=y_pred.flatten(),\n",
    "            marker=dict(\n",
    "                color='rgba(40, 40, 250, 0.3)',\n",
    "                size=5,\n",
    "            ),\n",
    "            name='Actual vs Predicted'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add a 45-degree line to show the perfect prediction\n",
    "    min_value = min(y_true.min(), y_pred.min())\n",
    "    max_value = max(y_true.max(), y_pred.max())\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_value, max_value],  # Adjusted x-axis range based on realistic range\n",
    "            y=[min_value, max_value],  # Adjusted y-axis range based on realistic range\n",
    "            mode='lines',\n",
    "            line=dict(color='red', dash='dash'),\n",
    "            showlegend=False,\n",
    "            name='Perfect Prediction Line'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Actual y2\",\n",
    "        yaxis_title=\"Predicted y2\",\n",
    "        width=700,\n",
    "        height=500,\n",
    "        xaxis=dict(range=[min_value, max_value]),  # Adjusted x-axis range\n",
    "        yaxis=dict(range=[min_value, max_value])   # Adjusted y-axis range\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "# Plot for model6 (y2)\n",
    "plot_actual_vs_predicted_y2(y2_test.values, y2_pred, \"Actual vs Predicted y2 Values (Model6)\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 230091,
     "status": "ok",
     "timestamp": 1725062980378,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "7lBNQLnp5Yhh",
    "outputId": "ec1ca6c4-d343-4e35-bf70-4d1fd93bd23e"
   },
   "source": [
    "# Extract the initial values from row 14 for columns X1-X50\n",
    "initial_values = data.iloc[13, 2:52].values  # Extracting X1-X50 from row 14\n",
    "\n",
    "# Define the optimization problem\n",
    "class F1F2Problem(Problem):\n",
    "    def __init__(self, model_y1, model_y2, initial_values):\n",
    "        n_var = 70  # Total number of features\n",
    "        xl_x1_x50 = initial_values  # Fix X1-X50\n",
    "        xu_x1_x50 = initial_values  # Fix X1-X50\n",
    "\n",
    "        # Define the range for X51-X70 (10 to 49)\n",
    "        xl_x51_x70 = np.full(20, 10)\n",
    "        xu_x51_x70 = np.full(20, 49)\n",
    "\n",
    "        # Combine all the variable bounds\n",
    "        xl = np.concatenate((xl_x1_x50, xl_x51_x70))\n",
    "        xu = np.concatenate((xu_x1_x50, xu_x51_x70))\n",
    "\n",
    "        super().__init__(n_var=n_var, n_obj=2, n_constr=0, xl=xl, xu=xu)\n",
    "        self.model_y1 = model_y1\n",
    "        self.model_y2 = model_y2\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        # Scale the input data\n",
    "        X_scaled = scaler.transform(X)\n",
    "        # Predict F1 and F2 using the trained MLP models\n",
    "        f1 = self.model_y1.predict(X_scaled)\n",
    "        f2 = self.model_y2.predict(X_scaled)\n",
    "        out[\"F\"] = np.column_stack([f1, f2])\n",
    "\n",
    "# Create the problem instance\n",
    "problem = F1F2Problem(model_y1=model5, model_y2=model6, initial_values=initial_values)\n",
    "\n",
    "# Define the algorithm with updated parameters\n",
    "algorithm = NSGA2(\n",
    "    pop_size=100,  # Increased population size\n",
    "    sampling=FloatRandomSampling(),\n",
    "    crossover=SBX(prob=0.95, eta=10),  # Increased crossover probability and decreased eta\n",
    "    mutation=PolynomialMutation(prob=0.25, eta=25)  # Increased mutation rate\n",
    ")\n",
    "\n",
    "# Set up colors for the different runs\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Set a fixed seed for all runs to make them identical\n",
    "fixed_seed = 42\n",
    "\n",
    "# Create a figure for the combined plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Loop to run the optimization 5 times and plot the Pareto fronts in different colors\n",
    "for i in range(5):\n",
    "    # Execute the optimization with the fixed seed\n",
    "    res = minimize(problem, algorithm, ('n_gen', 100), seed=fixed_seed+i, save_history=True, verbose=True)\n",
    "\n",
    "    # Plot the Pareto Frontier for this run in a different color\n",
    "    plt.scatter(res.F[:, 0], res.F[:, 1], color=colors[i], label=f'Run {i+1}')\n",
    "\n",
    "# Calculate the min and max values for f1 and f2 across all runs\n",
    "f1_min, f1_max = res.F[:, 0].min(), res.F[:, 0].max()\n",
    "f2_min, f2_max = res.F[:, 1].min(), res.F[:, 1].max()\n",
    "\n",
    "# Add some padding for better visualization\n",
    "f1_range = f1_max - f1_min\n",
    "f2_range = f2_max - f2_min\n",
    "\n",
    "plt.xlim(f1_min - 0.05 * f1_range, f1_max + 0.05 * f1_range)  # Set the range for f1 on the x-axis\n",
    "plt.ylim(f2_min - 0.05 * f2_range, f2_max + 0.05 * f2_range)  # Set the range for f2 on the y-axis\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Objective 1 (f1)')\n",
    "plt.ylabel('Objective 2 (f2)')\n",
    "plt.title('Pareto Front for NSGA-II with MLP Model')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K4r8noDi4jG_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1725064382439,
     "user_tz": -60,
     "elapsed": 1402074,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     }
    },
    "outputId": "31cb2a24-fa98-4b5b-b276-3890a013255c"
   },
   "source": [
    "# Model7 for y1\n",
    "# Prepare the data for model7 (y1)\n",
    "X = data.drop(columns=['y1', 'y2']).values\n",
    "y1 = data['y1'].values\n",
    "\n",
    "# Reshape X to be 3D as required by LSTM (samples, timesteps, features)\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Split the data into training and testing sets for y1\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "# Construct the LSTM model for y1 (model7)\n",
    "model7 = Sequential()\n",
    "model7.add(LSTM(64, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), activation='relu'))\n",
    "model7.add(Dropout(0.2))\n",
    "model7.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model7.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Train the model and measure time\n",
    "start_time_model7 = time.time()\n",
    "history7 = model7.fit(X_train_scaled, y1_train, validation_split=0.2, epochs=100, batch_size=32, verbose=1)\n",
    "end_time_model7 = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "train_time_model7 = end_time_model7 - start_time_model7\n",
    "print(f\"Training time for y1 model (model7): {train_time_model7} seconds\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss_model7 = model7.evaluate(X_test_scaled, y1_test)\n",
    "print(f\"Test MSE for model7 (y1): {test_loss_model7}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y1_pred_model7 = model7.predict(X_test_scaled)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "executionInfo": {
     "elapsed": 1477,
     "status": "ok",
     "timestamp": 1724446781238,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "neVkS09Y5V8M",
    "outputId": "012e369b-48b4-4b27-f817-329982421932"
   },
   "source": [
    "def plot_actual_vs_predicted(y_true, y_pred, title, xaxis_title, yaxis_title):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Actual vs. Predicted\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            mode='markers',\n",
    "            x=y_true,\n",
    "            y=y_pred.flatten(),  # Flattening y_pred to match y_true\n",
    "            marker=dict(\n",
    "                color='rgba(40, 40, 250, 0.3)',\n",
    "                size=5,\n",
    "            ),\n",
    "            name='Actual vs Predicted'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add a 45-degree line to show the perfect prediction\n",
    "    min_value = min(y_true.min(), y_pred.min())\n",
    "    max_value = max(y_true.max(), y_pred.max())\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_value, max_value],\n",
    "            y=[min_value, max_value],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', dash='dash'),\n",
    "            showlegend=False,\n",
    "            name='Perfect Prediction Line'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=xaxis_title,\n",
    "        yaxis_title=yaxis_title,\n",
    "        width=700,\n",
    "        height=500,\n",
    "        xaxis=dict(range=[min_value, max_value]),\n",
    "        yaxis=dict(range=[min_value, max_value])\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "# Plot the predicted vs actual values for y1 (Model7)\n",
    "plot_actual_vs_predicted(y1_test, y1_pred, \"Actual vs Predicted y1 Values (Model7)\", \"Actual y1\", \"Predicted y1\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0qEbNNo48ks",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1725065731075,
     "user_tz": -60,
     "elapsed": 1348643,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     }
    },
    "outputId": "4e117c9f-a20c-4f63-d0b5-1e2b6f0b97f3"
   },
   "source": [
    "# Model8 for y2\n",
    "# Prepare the data for model8 (y2)\n",
    "X = data.drop(columns=['y1', 'y2']).values\n",
    "y2 = data['y2'].values\n",
    "\n",
    "# Reshape X to be 3D as required by LSTM (samples, timesteps, features)\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Split the data into training and testing sets for y2\n",
    "X_train, X_test, y2_train, y2_test = train_test_split(X, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "# Construct the LSTM model for y2 (model8)\n",
    "model8 = Sequential()\n",
    "model8.add(LSTM(64, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), activation='relu'))\n",
    "model8.add(Dropout(0.2))\n",
    "model8.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model8.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Train the model and measure time\n",
    "start_time_model8 = time.time()\n",
    "history8 = model8.fit(X_train_scaled, y2_train, validation_split=0.2, epochs=100, batch_size=32, verbose=1)\n",
    "end_time_model8 = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "train_time_model8 = end_time_model8 - start_time_model8\n",
    "print(f\"Training time for y2 model (model8): {train_time_model8} seconds\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss_model8 = model8.evaluate(X_test_scaled, y2_test)\n",
    "print(f\"Test MSE for model8 (y2): {test_loss_model8}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y2_pred_model8 = model8.predict(X_test_scaled)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "executionInfo": {
     "elapsed": 1316,
     "status": "ok",
     "timestamp": 1724448501440,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "kCquzVJc5YaF",
    "outputId": "8a69f099-7c12-42b3-eab4-1cb928b3ed9d"
   },
   "source": [
    "# Plot the predicted vs actual values for y2 (Model8)\n",
    "def plot_actual_vs_predicted(y_true, y_pred, title, xaxis_title, yaxis_title):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Actual vs. Predicted\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            mode='markers',\n",
    "            x=y_true,\n",
    "            y=y_pred.flatten(),  # Flattening y_pred to match y_true\n",
    "            marker=dict(\n",
    "                color='rgba(40, 40, 250, 0.3)',\n",
    "                size=5,\n",
    "            ),\n",
    "            name='Actual vs Predicted'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add a 45-degree line to show the perfect prediction\n",
    "    min_value = min(y_true.min(), y_pred.min())\n",
    "    max_value = max(y_true.max(), y_pred.max())\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_value, max_value],\n",
    "            y=[min_value, max_value],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', dash='dash'),\n",
    "            showlegend=False,\n",
    "            name='Perfect Prediction Line'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=xaxis_title,\n",
    "        yaxis_title=yaxis_title,\n",
    "        width=700,\n",
    "        height=500,\n",
    "        xaxis=dict(range=[min_value, max_value]),\n",
    "        yaxis=dict(range=[min_value, max_value])\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "# Plot the predicted vs actual values for y2 (Model8)\n",
    "plot_actual_vs_predicted(y2_test, y2_pred, \"Actual vs Predicted y2 Values (Model8)\", \"Actual y2\", \"Predicted y2\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mWBM0Qvs6dCo",
    "outputId": "d1077f82-0c5c-4e9b-8dd7-f1a49030872f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1725066881477,
     "user_tz": -60,
     "elapsed": 485031,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     }
    }
   },
   "source": [
    "# Extract the initial values from row 14 for columns X1-X50\n",
    "initial_values = data.iloc[13, 2:52].values  # Extracting X1-X50 from row 14\n",
    "\n",
    "# Define the optimization problem\n",
    "class F1F2Problem(Problem):\n",
    "    def __init__(self, model_y1, model_y2, initial_values):\n",
    "        n_var = 70  # Total number of features\n",
    "        xl_x1_x50 = initial_values  # Fix X1-X50\n",
    "        xu_x1_x50 = initial_values  # Fix X1-X50\n",
    "\n",
    "        # Define the range for X51-X70 (10 to 49)\n",
    "        xl_x51_x70 = np.full(20, 10)\n",
    "        xu_x51_x70 = np.full(20, 49)\n",
    "\n",
    "        # Combine all the variable bounds\n",
    "        xl = np.concatenate((xl_x1_x50, xl_x51_x70))\n",
    "        xu = np.concatenate((xu_x1_x50, xu_x51_x70))\n",
    "\n",
    "        super().__init__(n_var=n_var, n_obj=2, n_constr=0, xl=xl, xu=xu)\n",
    "        self.model_y1 = model_y1\n",
    "        self.model_y2 = model_y2\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        # Reshape X to be 3D as required by LSTM (samples, timesteps, features)\n",
    "        X_reshaped = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "        # Scale the input data\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_reshaped.reshape(-1, X_reshaped.shape[-1])).reshape(X_reshaped.shape)\n",
    "\n",
    "        # Predict F1 and F2 using the trained LSTM models\n",
    "        f1 = self.model_y1.predict(X_scaled)\n",
    "        f2 = self.model_y2.predict(X_scaled)\n",
    "\n",
    "        # Filter out negative values by setting them to zero or a small positive value\n",
    "        f1[f1 < 0] = 0\n",
    "        f2[f2 < 0] = 0\n",
    "\n",
    "        out[\"F\"] = np.column_stack([f1, f2])\n",
    "\n",
    "# Create the problem instance for model7 and model8\n",
    "problem = F1F2Problem(model_y1=model7, model_y2=model8, initial_values=initial_values)\n",
    "\n",
    "# Define the algorithm with updated parameters\n",
    "algorithm = NSGA2(\n",
    "    pop_size=100,  # Population size\n",
    "    sampling=FloatRandomSampling(),\n",
    "    crossover=SBX(prob=0.95, eta=10),  # Crossover probability and eta\n",
    "    mutation=PolynomialMutation(prob=0.25, eta=25)  # Mutation rate\n",
    ")\n",
    "\n",
    "# Set up colors for the different runs\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Set a fixed seed for all runs to make them identical\n",
    "fixed_seed = 42\n",
    "\n",
    "# Create a figure for the combined plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Loop to run the optimization 5 times and plot the Pareto fronts in different colors\n",
    "for i in range(5):\n",
    "    # Execute the optimization with the fixed seed\n",
    "    res = minimize(problem, algorithm, ('n_gen', 200), seed=fixed_seed + i, save_history=True, verbose=True)\n",
    "\n",
    "    # Plot the Pareto Frontier for this run in a different color\n",
    "    plt.scatter(res.F[:, 0], res.F[:, 1], color=colors[i], label=f'Run {i+1}')\n",
    "\n",
    "# Calculate the min and max values for f1 and f2 across all runs\n",
    "f1_min, f1_max = res.F[:, 0].min(), res.F[:, 0].max()\n",
    "f2_min, f2_max = res.F[:, 1].min(), res.F[:, 1].max()\n",
    "\n",
    "# Add some padding for better visualization\n",
    "f1_range = f1_max - f1_min\n",
    "f2_range = f2_max - f2_min\n",
    "\n",
    "plt.xlim(f1_min - 0.05 * f1_range, f1_max + 0.05 * f1_range)  # Set the range for f1 on the x-axis\n",
    "plt.ylim(f2_min - 0.05 * f2_range, f2_max + 0.05 * f2_range)  # Set the range for f2 on the y-axis\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Objective 1 (f1)')\n",
    "plt.ylabel('Objective 2 (f2)')\n",
    "plt.title('Pareto Front for NSGA-II with LSTM Model')\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the optimization problem\n",
    "class F1F2Problem(Problem):\n",
    "    def __init__(self, model_y1, model_y2, initial_values, is_lstm=False):\n",
    "        n_var = 70  # Total number of features\n",
    "        xl_x1_x50 = initial_values  # Fix X1-X50\n",
    "        xu_x1_x50 = initial_values  # Fix X1-X50\n",
    "\n",
    "        # Define the range for X51-X70 (10 to 49)\n",
    "        xl_x51_x70 = np.full(20, 10)\n",
    "        xu_x51_x70 = np.full(20, 49)\n",
    "\n",
    "        # Combine all the variable bounds\n",
    "        xl = np.concatenate((xl_x1_x50, xl_x51_x70))\n",
    "        xu = np.concatenate((xu_x1_x50, xu_x51_x70))\n",
    "\n",
    "        super().__init__(n_var=n_var, n_obj=2, n_constr=0, xl=xl, xu=xu)\n",
    "        self.model_y1 = model_y1\n",
    "        self.model_y2 = model_y2\n",
    "        self.is_lstm = is_lstm\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "    # Scale the input data\n",
    "      scaler = StandardScaler()\n",
    "      X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "      if self.is_lstm:\n",
    "          # Reshape X_scaled to be 3D if the model is LSTM\n",
    "          X_scaled = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "      # Predict F1 and F2 using the trained models\n",
    "      f1 = self.model_y1.predict(X_scaled)\n",
    "      f2 = self.model_y2.predict(X_scaled)\n",
    "\n",
    "      # Filter out negative values by setting them to zero or a small positive value\n",
    "      f1[f1 < 0] = 0\n",
    "      f2[f2 < 0] = 0\n",
    "\n",
    "      out[\"F\"] = np.column_stack([f1, f2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract the initial values from row 14 for columns X1-X50\n",
    "initial_values = data.iloc[13, 2:52].values  # Extracting X1-X50 from row 14\n",
    "\n",
    "# Define the algorithm with updated parameters\n",
    "algorithm = NSGA2(\n",
    "    pop_size=100,  # Population size\n",
    "    sampling=FloatRandomSampling(),\n",
    "    crossover=SBX(prob=0.95, eta=10),  # Crossover probability and eta\n",
    "    mutation=PolynomialMutation(prob=0.25, eta=25)  # Mutation rate\n",
    ")\n",
    "\n",
    "# Set up markers and colors for the different models\n",
    "markers = ['s', 'o', 'D', '^']  # Square, circle, diamond, triangle\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "# Create a figure for the combined plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# List of model combinations and LSTM flag\n",
    "model_combinations = [\n",
    "    (model1, model2, False),  # Lasso\n",
    "    (model3, model4, False),  # XGBoost\n",
    "    (model5, model6, False),  # MLP\n",
    "    (model7, model8, True)    # LSTM\n",
    "]\n",
    "\n",
    "# Variables to track the min and max values for f1 and f2\n",
    "f1_min, f1_max = np.inf, -np.inf\n",
    "f2_min, f2_max = np.inf, -np.inf\n",
    "\n",
    "# Loop to run the optimization for each model combination and plot the Pareto fronts\n",
    "for idx, (model_y1, model_y2, is_lstm) in enumerate(model_combinations):\n",
    "    # Instantiate the problem with the current model combination\n",
    "    problem = F1F2Problem(model_y1=model_y1, model_y2=model_y2, initial_values=initial_values, is_lstm=is_lstm)\n",
    "\n",
    "    # Execute the optimization with a fixed seed for reproducibility\n",
    "    res = minimize(problem, algorithm, ('n_gen', 100), seed=42, save_history=True, verbose=True)\n",
    "\n",
    "    # Update the min and max values for f1 and f2\n",
    "    f1_min = min(f1_min, res.F[:, 0].min())\n",
    "    f1_max = max(f1_max, res.F[:, 0].max())\n",
    "    f2_min = min(f2_min, res.F[:, 1].min())\n",
    "    f2_max = max(f2_max, res.F[:, 1].max())\n",
    "\n",
    "    # Plot the Pareto Frontier for this model combination\n",
    "    plt.scatter(res.F[:, 0], res.F[:, 1], color=colors[idx], marker=markers[idx], label=f'Model Set {idx+1}', s=100)\n",
    "\n",
    "# Add some padding for better visualization\n",
    "f1_range = f1_max - f1_min\n",
    "f2_range = f2_max - f2_min\n",
    "\n",
    "plt.xlim(f1_min - 0.05 * f1_range, f1_max + 0.05 * f1_range)  # Dynamically set the range for f1 on the x-axis\n",
    "plt.ylim(f2_min - 0.05 * f2_range, f2_max + 0.05 * f2_range)  # Dynamically set the range for f2 on the y-axis\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Objective 1 (f1)')\n",
    "plt.ylabel('Objective 2 (f2)')\n",
    "plt.title('Comparison of Pareto Fronts from Different Model Combinations')\n",
    "plt.legend(labels=['Lasso (Model 1 & 2)', 'XGBoost (Model 3 & 4)', 'MLP (Model 5 & 6)', 'LSTM (Model 7 & 8)'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XEI2_hqtfgTJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1725066395490,
     "user_tz": -60,
     "elapsed": 113460,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     }
    },
    "outputId": "6393d9a3-bb9b-44b2-daf6-d03cce35e313"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1724448761774,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "OX0eULeW9dUv",
    "outputId": "52b3ab6f-2d9a-4ad3-98ba-001ad53f2284"
   },
   "source": [
    "# Convert training time from seconds to minutes\n",
    "train_time_model5_minutes = train_time_model5 / 60\n",
    "train_time_model7_minutes = train_time_model7 / 60\n",
    "\n",
    "# Data for plotting\n",
    "models_57 = ['Model 5', 'Model 7']\n",
    "training_times_57 = [train_time_model5_minutes, train_time_model7_minutes]\n",
    "test_losses_57 = [test_loss_model5, test_loss_model7]\n",
    "\n",
    "# Set up the color palette\n",
    "palette = sns.color_palette(\"husl\", 2)\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot the training time as a bar chart on the left y-axis\n",
    "ax1.bar(models_57, training_times_57, color=palette[0], alpha=0.6, label='Training Time (min)')\n",
    "ax1.set_xlabel('Models', fontsize=14)\n",
    "ax1.set_ylabel('Training Time (min)', fontsize=14, color=palette[0])\n",
    "ax1.tick_params(axis='y', labelcolor=palette[0])\n",
    "ax1.set_ylim(0, max(training_times_57) * 1.1)  # Start y-axis from 0\n",
    "\n",
    "# Create the second y-axis for test MSE\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(models_57, test_losses_57, color=palette[1], marker='o', linestyle='-', linewidth=2, label='Test MSE')\n",
    "ax2.set_ylabel('Test MSE', fontsize=14, color=palette[1])\n",
    "ax2.tick_params(axis='y', labelcolor=palette[1])\n",
    "ax2.set_ylim(0, max(test_losses_57) * 1.1)  # Start y-axis from 0\n",
    "\n",
    "# Add a title and grid\n",
    "plt.title('Comparison of Training Time and Test MSE (Model 5 vs Model 7)', fontsize=16)\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout to ensure everything fits without overlap\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1724448762385,
     "user": {
      "displayName": "Felix You",
      "userId": "02395976694846081543"
     },
     "user_tz": -60
    },
    "id": "toxiWeVX-PA_",
    "outputId": "7494c7f7-a504-497a-b8d7-9acd9d2f5bc0"
   },
   "source": [
    "# Convert training time from seconds to minutes\n",
    "train_time_model6_minutes = train_time_model6 / 60\n",
    "train_time_model8_minutes = train_time_model8 / 60\n",
    "\n",
    "# Data for plotting\n",
    "models_68 = ['Model 6', 'Model 8']\n",
    "training_times_68 = [train_time_model6_minutes, train_time_model8_minutes]\n",
    "test_losses_68 = [test_loss_model6, test_loss_model8]\n",
    "\n",
    "# Set up the color palette\n",
    "palette = sns.color_palette(\"husl\", 2)\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot the training time as a bar chart on the left y-axis\n",
    "ax1.bar(models_68, training_times_68, color=palette[0], alpha=0.6, label='Training Time (min)')\n",
    "ax1.set_xlabel('Models', fontsize=14)\n",
    "ax1.set_ylabel('Training Time (min)', fontsize=14, color=palette[0])\n",
    "ax1.tick_params(axis='y', labelcolor=palette[0])\n",
    "ax1.set_ylim(0, max(training_times_68) * 1.1)  # Start y-axis from 0\n",
    "\n",
    "# Create the second y-axis for test MSE\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(models_68, test_losses_68, color=palette[1], marker='o', linestyle='-', linewidth=2, label='Test MSE')\n",
    "ax2.set_ylabel('Test MSE', fontsize=14, color=palette[1])\n",
    "ax2.tick_params(axis='y', labelcolor=palette[1])\n",
    "ax2.set_ylim(0, max(test_losses_68) * 1.1)  # Start y-axis from 0\n",
    "\n",
    "# Add a title and grid\n",
    "plt.title('Comparison of Training Time and Test MSE (Model 6 vs Model 8)', fontsize=16)\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout to ensure everything fits without overlap\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyMrqPiqbhIMV1deJ1Rh2pIe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
